# Kickstarter Analysis

### Background

Over two billion dollars have been raised using the massively successful crowdfunding service, Kickstarter, but not every project has found success. Of the over 300,000 projects launched on Kickstarter, only a third have made it through the funding process with a positive outcome.

Since getting funded on Kickstarter requires meeting or exceeding the project's initial goal, many organizations spend months looking through past projects in an attempt to discover some trick to finding success.

### Objectives

This is an Excel Analysis of four thousand past Kickstarter projects to uncover hidden trends by examining the funding process and success rate.

### Conclusions
After analysis of the provided data, it is evident that overall, Kickstarter campaigns are more likely to be successful than they are to fail or be canceled. With the provided data, 2,185 projects out of the total 4,114 projects (53.1%) were successful, while 1,530 (37.1%) failed and 349 (8.4%) were cancelled. Upon further analysis of only the successful and failed campaigns, there is a significant decrease in likelihood of success based on the category of the campaign. The three most successful categories of campaigns are music (81%), theater (63%), and film and video (63%). The three least successful categories of campaigns are publishing (37%), games (36%), and food (20%). In addition to these observations, when looking at the outcomes of technology campaigns, 178 (30%) campaigns are canceled, 213 (35%) campaigns have failed, and only 209 (35%) are successful. With this information, key stakeholders and backers would need to take careful consideration before committing to backing these types of campaigns due to their increased likelihood of cancellation and failure. Backers of music, theater, and film can feel much more confident in their decision to back those categories of campaigns, given the data that was provided.

When the data is further broken down into subcategories of campaigns, there are even larger gaps in the trends of successful and unsuccessful campaigns. Classical music, documentary, electronic music, hardware, metal, nonfiction, radio and podcasts, rock, shorts, small batch, tabletop games, and television all have a 100% success rate, while animation, childrenâ€™s books, drama, faith, fiction, food trucks, gadgets, jazz, mobile games, nature, places, restaurants, translations, video games, and web all have a 100% failure rate. Due to the sample sizes of these respective subcategories, these success and failure rates are extremely skewed, therefore a definitive observation cannot be made about the likelihood of success of these subcategories. More data and an increased sample size could lead to a better determination for backers to make a decision based on their likelihood of success.

Upon looking at the success rates by month, there are a few notable trends in the data. The first trend is that the rate of canceled projects stays relatively the same throughout the entire year. There are far fewer fluctuations in rate of canceled campaigns, than there are of successful and failed campaigns. The second notable trend is that there is a significant decrease in the likelihood of success of a campaign after May. The month of May sees a spike in the likelihood of success, then a steep decrease until September. What this could suggest to backers is that they consider backing campaigns beginning in the first few months of the year, and take more careful consideration when planning to back a campaign in the latter half of the year. The final notable trend is that the month of December is the only month of the year that sees a higher failure rate of campaigns than success rate. This suggests that backers should only consider backing campaigns during this month that historically have high rates of success due to the increased likelihood of failure of campaigns overall.

### Limitations
The first limitation of this data is that we only have data for one crowdfunding source. In order to make more accurate observations based on success rates of certain categories of campaigns, we would need to look at various crowdfunding sources to see if there was a significant difference in success and failure rates of these types of campaigns. This leads to a second limitation of the data, which is that the sample size is too small to make a concrete assumption of success rates. Based on the conclusions of campaigns when broken down into subcategories, it is clear that the sample sizes are too small to make an accurate observation of the success rates. More data from various sources would allow for more confidence when suggesting potential options for backers.

### Further Analysis
Because of the steep decrease in rates of success after the month of May, it would be interesting to further analyze why this occurs. More data from various crowdfunding sources, in addition to potential various locations of these campaigns, could lead to a better understanding of why this steep decrease of success occurs during those months.

Further investigation of the owners of these campaigns could lead to a more accurate analysis of these success rates as well. Provided more context, there could be a significance based on the experience of the people who start these campaigns, their geographic location, and potentially their own socioeconomic status. Many factors could be present in the determination of whether their campaigns are successful or unsuccessful.

Finally, more information after these campaigns are deemed successful could be interesting. Based on this data, a campaign is considered successful if they are able to crowdfund enough money to meet their goals. There is no data on whether the project was successful after the goal was met. This information would be helpful to give to backers in order to help them make a more informed decision about what campaigns they support.
